[
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "",
    "text": "Since the outbreak of COVID-19, many countries have rushed to create a vaccine and ensure its population is well immunized against this novel coronavirus. On 13 January 2021, the mass immunisation program commenced and since then Indonesia ranks third in Asia and fifth in the world in terms of total doses given.\nIn this take-home assignment, we will be exploring vaccination rates in DKI Jarkarta, identifying sub-districts with relatively higher number of vaccination rate and how they changed over time.\nThe tasks given to us is as follows:\nChoropleth Mapping and Analysis\n\nCompute the monthly vaccination rate from July 2021 to June 2022 at sub-district (also known as kelurahan in Bahasa Indonesia) level,\nPrepare the monthly vaccination rate maps by using appropriate tmap functions,\nDescribe the spatial patterns revealed by the choropleth maps (not more than 200 words).\n\nLocal Gi* Analysis\nWith reference to the vaccination rate maps prepared in ESDA:\n\nCompute local Gi* values of the monthly vaccination rate,\nDisplay the Gi* maps of the monthly vaccination rate. The maps should only display the significant (i.e. p-value < 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 250 words).\n\nEmerging Hot Spot Analysis(EHSA)\nWith reference to the local Gi* values of the vaccination rate maps prepared in the previous section:\n\nPerform Mann-Kendall Test by using the spatio-temporal local Gi* values,\nSelect three sub-districts and describe the temporal trends revealed (not more than 250 words), and\nPrepared a EHSA map of the Gi* values of vaccination rate. The maps should only display the significant (i.e. p-value < 0.05).\nWith reference to the EHSA map prepared, describe the spatial patterns revelaed. (not more than 250 words).\n\nThroughout this page, each step will be explained and guided so that you can follow along."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#packages-used",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#packages-used",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "2.1 Packages Used",
    "text": "2.1 Packages Used\nThe R packages used for this analysis are:\n\nsf\ntidyverse\nspatstat\ntmap\nsfdep\nmaptools\nreadxl\n\nThe code chunk below checks whether the packages have been installed, if not it will automatically install them and load the packages into Rstudio.\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, sfdep, maptools, readxl, spdep)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#the-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#the-data",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "2.2 The Data",
    "text": "2.2 The Data\n\n\n\nType\nName\nFormat\nDescription\n\n\n\n\nGeospatial\nBatas Desa Provinsi DKI Jakarta\nshapefile\nSub-districts in DKI Jakarta\n\n\nAspatial\nRiwayat File Vaksinasi DKI Jakarta\n.xlsx\nSub-district level data of vaccination numbers between July 2021 to June 2022\n\n\n\n\nGeospatial Data\n\nThe link under Geospatial Data above brings you to a page where there are many download links sorted by province. Ensure that you are using Shapefile (SHP) Batas Desa Provinsi DKI Jakarta.\n\nAspatial Data\n\nThe link under Aspatial Data above brings you to a page where there are two types of data files you can use. Please choose Data Vaksinasi Berbasis Kelurahan dan Kecamatan and download a total of 12 files beginning July 2021 to June 2022.\nDo note that we will be using the beginning of each month for our download."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#geospatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#geospatial-data",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "3.1 Geospatial Data",
    "text": "3.1 Geospatial Data\n\n3.1.1 Import Geospatial Data\n\ngeoDKI <- st_read(dsn = \"data/geospatial\",\n                    layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\")\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `/Users/junhaoteo/Documents/junhao2309/IS415/Take-Home_Ex/Take-Home_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nFrom the output above, we can see that the data set has a geometry type, Multipolygon, and has 269 features and 161 fields.\n\n\n3.1.2 Check for invalid geometries\nBefore we begin, we should check whether there are any invalid geometries by using the code chunk below:\n\nst_is_valid(geoDKI)\n\n  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [31] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [46] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [61] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [76] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n [91] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[106] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[121] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[136] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[151] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[166] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[181] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[196] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[211] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[226] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[241] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n[256] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\n\nst_is_valid() from the sf package helps to check whether a geometry is valid. From the output, there are no invalid geometries.\n\n\n3.1.3 Check for Missing values\nThe code chunk below uses is.na() from base R checks whether the data set has NA values. which() from base R takes the indices of these values and lastly length() helps us calculate the length of the data objects.\n\nlength(which(is.na(geoDKI) == TRUE))\n\n[1] 14\n\n\nIn the above output, there are 14 NA values within the jakarta data set.\nTo remove them, we can simply use na.exclude to delete the rows with NA values\n\ngeoDKI <- na.omit(geoDKI)\n\nWe can run the same code to see whether all NA values have been removed.\n\nlength(which(is.na(geoDKI) == TRUE))\n\n[1] 0\n\n\nNice! All NA values have been removed.\n\n\n3.1.4 Check Coordinate System\nAs different countries use different projection systems, we need to first check the CRS of jakarta.\nThe code chunk below uses st_crs() from the sf package:\n\nst_crs(geoDKI)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nWe notice that jakarta is using EPSG::4326 which is the wrong projection coordinate system. DKI Jakarta uses the DGN95, the ‘Datum Geodesi Nasional 1995’, EPSG::23878\nWe can transform the crs by using st_transform() from the sf package:\n\ngeoDKI <- geoDKI %>%\n  st_transform(crs = 23878)\n\n\nst_crs(geoDKI)\n\nCoordinate Reference System:\n  User input: EPSG:23878 \n  wkt:\nPROJCRS[\"DGN95 / UTM zone 48S\",\n    BASEGEOGCRS[\"DGN95\",\n        DATUM[\"Datum Geodesi Nasional 1995\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4755]],\n    CONVERSION[\"UTM zone 48S\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",105,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",10000000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Indonesia - south of equator and between 102°E and 108°E - onshore and offshore.\"],\n        BBOX[-10.73,102,0,108.01]],\n    ID[\"EPSG\",23878]]\n\n\nFrom the output above, we can see that the CRS has been properly assigned.\n\n\n3.1.5 Removing Outer Islands\nLet us visualise the geographical polygons.\n\nqtm(geoDKI)\n\n\n\n\nWe can see from the output that jakarta includes both the mainland and the outer islands. Our study area focuses only on the mainland and thus we need to remove them.\n\nView(geoDKI)\n\nBefore we continue further, we need to understand how DKI Jakarta geographical regions are segmented. The code chunk above lets you view the entire dataset. Let us understand the key variables below:\nWith the help of uncle google, we will translate the names.\n\n\n\nName\nTranslation\n\n\n\n\nKODE_DESA\nVillage Code\n\n\nDESA\nVillage\n\n\nPROVINSI\nProvince\n\n\nKAB_KOTA\nCity\n\n\nKECAMATAN\nDistrict\n\n\nDESA_KELUR\nSub-District\n\n\n\nKAB_KOTA would be the most logical choice in isolating out the outer islands.\nThe code chunk below helps to output unique values in KAB_KOTA field.\n\nunique(geoDKI$KAB_KOTA)\n\n[1] \"JAKARTA BARAT\"    \"JAKARTA PUSAT\"    \"KEPULAUAN SERIBU\" \"JAKARTA UTARA\"   \n[5] \"JAKARTA TIMUR\"    \"JAKARTA SELATAN\" \n\n\nThe output above shows that there are 6 major cities in DKI Jakarta.\nThe codechunk below will visualize the data with respect to the 6 major cities. We can then see which city isolates out the outer islands.\n\ntmap_mode(\"plot\")\ntm_shape(geoDKI) +\n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\nFrom the visualization above, we can see that KEPULAUAN SERIBU is not part of the mainland. We can then use filter() from dplyr package to remove the outer islands.\n\ngeoDKI <- filter(geoDKI, KAB_KOTA !=\"KEPULAUAN SERIBU\")\n\n\ntm_shape(geoDKI) + \n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\nNow we can see that our shapefile only contains the mainland, which is our study area.\nNow, before we move on, geoDKI has alot of columns. Since we are only interested in the subdistrict level, we will select we will select those that are relevant to our analysis and rename them:\n\ngeoDKI <- geoDKI %>%\n  select(7, \"geometry\") %>%\n  rename(subdistrict=`KECAMATAN`)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#aspatial-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#aspatial-data",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "3.2 Aspatial Data",
    "text": "3.2 Aspatial Data\n\n3.2.1 Import Aspatial Data\nBefore we import the data in, the file names are rather long. First, go to your data folder and change the aspatial data file names to Y-M format. It would look like this:\n\n\n\n\n\nThere are a total of 12 excel files we need to load into Rstudio. To read the files more efficiently, we will use the “for loop” function to read all the excel files into a data frame by using the read_excel() from the readxl package.\n\n# Set the working directory to the folder containing the Excel files\nsetwd(\"data/aspatial/\")\n# Get a list of all Excel files in the directory\naspatial_data <- list.files(pattern = \".xlsx\")\n\n# Loop through the files and read each one into a data frame\nfor (i in aspatial_data) {\n  assign(gsub(\".xlsx\", \"\", i), read_excel(i))\n}\n\n\n\n3.2.2 Columns of interest and its translation\nIn the aspatial data set, what we want is the total vaccination and not vaccinated numbers, along with these 4 regional classification columns.\n\nnames(`2022-6`)\n\n [1] \"KODE KELURAHAN\"                            \n [2] \"WILAYAH KOTA\"                              \n [3] \"KECAMATAN\"                                 \n [4] \"KELURAHAN\"                                 \n [5] \"SASARAN\"                                   \n [6] \"BELUM VAKSIN\"                              \n [7] \"JUMLAH\\r\\nDOSIS 1\"                         \n [8] \"JUMLAH\\r\\nDOSIS 2\"                         \n [9] \"JUMLAH\\r\\nDOSIS 3\"                         \n[10] \"TOTAL VAKSIN\\r\\nDIBERIKAN\"                 \n[11] \"LANSIA\\r\\nDOSIS 1\"                         \n[12] \"LANSIA\\r\\nDOSIS 2\"                         \n[13] \"LANSIA\\r\\nDOSIS 3\"                         \n[14] \"LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN\"         \n[15] \"PELAYAN PUBLIK\\r\\nDOSIS 1\"                 \n[16] \"PELAYAN PUBLIK\\r\\nDOSIS 2\"                 \n[17] \"PELAYAN PUBLIK\\r\\nDOSIS 3\"                 \n[18] \"PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN\"  \n[19] \"GOTONG ROYONG\\r\\nDOSIS 1\"                  \n[20] \"GOTONG ROYONG\\r\\nDOSIS 2\"                  \n[21] \"GOTONG ROYONG\\r\\nDOSIS 3\"                  \n[22] \"GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN\"   \n[23] \"TENAGA KESEHATAN\\r\\nDOSIS 1\"               \n[24] \"TENAGA KESEHATAN\\r\\nDOSIS 2\"               \n[25] \"TENAGA KESEHATAN\\r\\nDOSIS 3\"               \n[26] \"TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN\"\n[27] \"TAHAPAN 3\\r\\nDOSIS 1\"                      \n[28] \"TAHAPAN 3\\r\\nDOSIS 2\"                      \n[29] \"TAHAPAN 3\\r\\nDOSIS 3\"                      \n[30] \"TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN\"       \n[31] \"REMAJA\\r\\nDOSIS 1\"                         \n[32] \"REMAJA\\r\\nDOSIS 2\"                         \n[33] \"REMAJA\\r\\nDOSIS 3\"                         \n[34] \"REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN\"          \n\n\n\n\n\nName\nTranslation\n\n\n\n\nKODE KELURAHAN\nVillage Code\n\n\nWILAYAH KOTA\nCity Region\n\n\nKECAMATAN\nSub-District\n\n\nKELURAHAN\nWard\n\n\nTOTAL VAKSIN\\r\\nDIBERIKAN\nTotal Vaccination\n\n\nBELUM VAKSIN\nNot Vaccinated\n\n\n\n\n\n3.2.3 Mutate Aspatial Data\n\n3.2.3.1 Mutating using for loop\nAs there are 12 data sets, we will use the for loop that mutate, rename and select the fields that we want. The code chunk below does the following:\n\nRenames KODE KELURAHAN, WILAYAH KOTA, KECAMATAN, KELURAHAN, TOTAL VAKSIN\\r\\nDIBERIKAN and BELUM VAKSIN to village_code, city_region, subdistrict, ward, total_vaccination and not_vaccinated respectively by using rename() from the dplyr package\nSelects the renamed columns by using select() from the dplyr package\nAdds a date column by using mutate() from the dplyr package\n\nAll the mutated aspatial data frames are then placed into a list\n\nlist_mth<- list(`2021-7`,`2021-8`,`2021-9`,`2021-10`,`2021-11`,`2021-12`,`2022-1`,`2022-2`,`2022-3`,`2022-4`,`2022-5`,`2022-6`)\n\ndate <- c(\"2021-07-01\", \"2021-08-01\", \"2021-09-01\", \"2021-10-01\", \"2021-11-01\", \"2021-12-01\", \"2022-01-01\", \"2022-02-01\", \"2022-03-01\", \"2022-04-01\", \"2022-05-01\", \"2022-06-01\")\n\nlists <- list()\nfor (i in c(1:12)){\n  lists[[i]]<- list_mth[[i]] %>% \n    rename(city_region =`WILAYAH KOTA`, \n           subdistrict=`KECAMATAN`, \n           total_vaccination= `TOTAL VAKSIN\\r\\nDIBERIKAN`, \n           not_vaccinated =`BELUM VAKSIN`) %>% \n  select(city_region, subdistrict, not_vaccinated ,total_vaccination) %>%\n    mutate(date = as.Date(date[i]), \n           .before=1)\n}\n\n\n\n3.2.3.2 Combine into a single dataframe from a list of dataframes\nAfterwhich, we can use Reduce() and rbind from base R to join all dataframes in the lists as one dataframe.\nThe code chunk below does this:\n\naspatial_data <- Reduce(rbind, lists)\nglimpse(aspatial_data)\n\nRows: 3,216\nColumns: 5\n$ date              <date> 2021-07-01, 2021-07-01, 2021-07-01, 2021-07-01, 202…\n$ city_region       <chr> NA, \"JAKARTA UTARA\", \"JAKARTA BARAT\", \"JAKARTA TIMUR…\n$ subdistrict       <chr> NA, \"PADEMANGAN\", \"TAMBORA\", \"KRAMAT JATI\", \"JATINEG…\n$ not_vaccinated    <dbl> 5041111, 13272, 16477, 18849, 5743, 15407, 12503, 11…\n$ total_vaccination <dbl> 3877757, 10401, 12520, 8945, 4454, 11342, 9125, 1365…\n\n\nWe can see from the output that we have the columns that we want in its new name and having 3216 rows.\nFrom the glimpse output, we can see that there are NA values inside the dataframe. If you View the original individual files, you will notice that there will be a row that calculates the total of a respective column and that row contains NA values.\n\n\n3.2.3.3 Final steps to take\nSo these are the steps to take,\n\nRemove the NA rows in the dataframe\nFilter out the outer islands\n\nYou will notice from the output of the code chunk below that outer islands is categorised as KAB.ADM.KEP.SERIBU\n\n\n\nunique(aspatial_data$city_region)\n\n[1] NA                   \"JAKARTA UTARA\"      \"JAKARTA BARAT\"     \n[4] \"JAKARTA TIMUR\"      \"JAKARTA SELATAN\"    \"JAKARTA PUSAT\"     \n[7] \"KAB.ADM.KEP.SERIBU\"\n\n\n\nAdd in total population and vaccination rate columns\n\nFormula:\n\n\nThe code chunk below does this:\n\naspatial_data <- aspatial_data %>%\n  na.exclude() %>%\n  filter(city_region != \"KAB.ADM.KEP.SERIBU\") %>% \n  mutate(total_population = total_vaccination + not_vaccinated, vaccination_rate = total_vaccination/total_population) %>%\n  select(date, subdistrict, vaccination_rate)\n\nBefore we join both aspatial and geospatial data, we have to check whether the subdistrict names match between files. To do so, we will use setdiff() from the dplyr package:\n\nsetdiff(aspatial_data$subdistrict, geoDKI$subdistrict)\n\n[1] \"KRAMAT JATI\" \"PULO GADUNG\" \"SETIA BUDI\"  \"PALMERAH\"    \"KALI DERES\" \n\n\n\nsetdiff(geoDKI$subdistrict, aspatial_data$subdistrict)\n\n[1] \"KALIDERES\"  \"PAL MERAH\"  \"SETIABUDI\"  \"PULOGADUNG\" \"KRAMATJATI\"\n\n\nFrom the output above, we can compare and see that these names usually differ by a spacing. The first output shows the names in aspatial_data while the second output show the names in geoDKI. We will amend geoDKI to match the names in the aspatial_data.\n\nn1 <- which(geoDKI$subdistrict == \"KRAMATJATI\")\nn2 <- index <- which(geoDKI$subdistrict == \"PAL MERAH\")\nn3 <- index <- which(geoDKI$subdistrict == \"PULOGADUNG\")\nn4 <- index <- which(geoDKI$subdistrict == \"SETIABUDI\")\nn5 <- index <- which(geoDKI$subdistrict == \"KALIDERES\")\nfor (i in n1) {\n  geoDKI$subdistrict[i] <- \"KRAMAT JATI\"\n}\nfor (i in n2) {\n  geoDKI$subdistrict[i] <- \"PALMERAH\"\n}\nfor (i in n3) {\n  geoDKI$subdistrict[i] <- \"PULO GADUNG\"\n}\nfor (i in n4) {\n  geoDKI$subdistrict[i] <- \"SETIA BUDI\"\n}\nfor (i in n5) {\n  geoDKI$subdistrict[i] <- \"KALI DERES\"\n}\n\nDone! Now we can just do the same check, we will notice that the output is character(0) meaning that both columns names have matched.\n\nsetdiff(aspatial_data$subdistrict, geoDKI$subdistrict)\n\ncharacter(0)\n\n\n\nvaccination <- left_join(aspatial_data, geoDKI, \n                         by = \"subdistrict\")\n\n\nvaccination <- st_as_sf(vaccination) %>%\n  mutate(date = as.factor(date))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualizing-the-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualizing-the-data",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "4.1 Visualizing the data",
    "text": "4.1 Visualizing the data\n\n4.1.1 R Shiny\nSomething extra to this TakeHome Assignment will be the use of the ShinyApp. This is a short introduction as to how Rshiny works:\n\nDefine the UI:\n\nYou will have an input and in this case, we will use selectInput(“dates”, “Pick a month”, date, selected = “July 2021”,multiple = FALSE).\n\n“dates”: This is the variable name to call into the output portion in the server\n“Pick a month”: This is a text under the user interface to ask the user to pick a choice\ndate: This is the vector of choices that they can pick from.\nselected = “July 2021” : This sets the choice “July 2021” as the default when starting up the app\nmultiple = FALSE : Prevents the user from picking multiple options and can only choose 1\n\n\nDefine Server:\n\nThis is where tmap is used and calls upon the variable name defined in UI which is “dates”.\n\n\n\nlibrary(shiny)\n\ndate <- c(\"July 2021\", \"August 2021\", \"September 2021\", \"October 2021\", \"November 2021\", \"December 2021\", \"January 2022\", \"February 2022\", \"March 2022\", \"April 2022\", \"May 2022\", \"June 2022\")\n# Define the UI\nui <- fluidPage(\n  selectInput(\"dates\", \"Pick a month\",\n              date, selected = \"July 2021\",\n              multiple = FALSE),\n  \n  tmapOutput(\"my_map\")\n)\n\n# Define the server\nserver <- function(input, output) {\n  # Render the tmap in the output element\n  output$my_map <- renderTmap({\n    a <- vaccination |>\n      filter(date == input$dates)\n\n    tm_shape(a) +\n  tm_fill(\"vaccination_rate\",\n          style = \"quantile\",\n          palette =\"Blues\")\n  })\n}\n\n# Run the app\nshinyApp(ui, server)\n\nRefer to visual plot : ShinyApp\nNote: There are many ways to create and design the shiny app, under the user interface. One example is using a sliderInput() to let the user their zoom level. This can be found under R shiny documentation.\n\n\n4.1.2 Tmap Visualization\nConsidering we have 12 months of Tmap visualization to do, it would be better to create a tmap function.\nThe code chunk below first filters out vaccination dataframe into their respective months and then inputs the filtered dataframe into the tm_shape().\n\ngraphing <- function(x){\n  a <- vaccination %>%\n    filter(date == x)\n  tm_shape(a) +\n  tm_fill(\"vaccination_rate\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = paste(x),\n            main.title.position = \"left\",\n            legend.height = 0.8, \n            legend.width = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_grid(alpha =0.2)\n}\n\nWe will split the plots into 2 code chunks to reduce the number of graphs in a single output for a clearer view.\n\ntmap_mode(\"plot\")\ntmap_arrange(graphing(\"2021-07-01\"),\n             graphing(\"2021-08-01\"),\n             graphing(\"2021-09-01\"),\n             graphing(\"2021-10-01\"),\n             graphing(\"2021-11-01\"),\n             graphing(\"2021-12-01\"),\n             ncol = 2)\n\n\n\n\n\ntmap_arrange(graphing(\"2022-01-01\"),\n             graphing(\"2022-02-01\"),\n             graphing(\"2022-03-01\"),\n             graphing(\"2022-04-01\"),\n             graphing(\"2022-05-01\"),\n             graphing(\"2022-06-01\"),\n             ncol = 2)\n\n\n\n\nLikewise, this can be done on Rshiny app but this will be covered on a later date when I have attended the Rshiny workshop. :)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#spatial-patterns-observed-200words",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#spatial-patterns-observed-200words",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "4.2 Spatial Patterns observed (200words)",
    "text": "4.2 Spatial Patterns observed (200words)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-contiguity-spatial-weights",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-contiguity-spatial-weights",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "5.1 Computing Contiguity Spatial Weights",
    "text": "5.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct the spatial weights of the study area.\nSpatial weights: Used to define the neighbourhood relationships between geographical units in the study area.\nAs we are dealing with 12 different months of vaccination rates, we will have to filter the dataframe to their respective months and calculate their respective weights. Here, we will be using the QUEEN mode and thus the argument: queen =TRUE. The code chunk below shows the function that filters to the selected month and then calculate their weights.\n\nmonth <- vaccination %>%\n  filter(date == \"2021-07-01\")\nwm_q <- month %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before=1)\nwm_q\n\nSimple feature collection with 1733 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 686587.9 ymin: 9295420 xmax: 718314.5 ymax: 9326648\nProjected CRS: DGN95 / UTM zone 48S\n# A tibble: 1,733 × 6\n   nb         wt         date       subdistr…¹ vacci…²                  geometry\n * <nb>       <list>     <fct>      <chr>        <dbl>        <MULTIPOLYGON [m]>\n 1 <int [36]> <dbl [36]> 2021-07-01 PADEMANGAN   0.439 (((705374.9 9319867, 705…\n 2 <int [18]> <dbl [18]> 2021-07-01 PADEMANGAN   0.439 (((703435.4 9320774, 703…\n 3 <int [56]> <dbl [56]> 2021-07-01 PADEMANGAN   0.439 (((706161.9 9323032, 706…\n 4 <int [65]> <dbl [65]> 2021-07-01 TAMBORA      0.432 (((699986.5 9320097, 699…\n 5 <int [73]> <dbl [73]> 2021-07-01 TAMBORA      0.432 (((700048.7 9320815, 700…\n 6 <int [56]> <dbl [56]> 2021-07-01 TAMBORA      0.432 (((699332.3 9319111, 699…\n 7 <int [65]> <dbl [65]> 2021-07-01 TAMBORA      0.432 (((700076.3 9319167, 699…\n 8 <int [84]> <dbl [84]> 2021-07-01 TAMBORA      0.432 (((700480.1 9320083, 700…\n 9 <int [68]> <dbl [68]> 2021-07-01 TAMBORA      0.432 (((699283.3 9320010, 699…\n10 <int [44]> <dbl [44]> 2021-07-01 TAMBORA      0.432 (((699268 9320073, 69927…\n# … with 1,723 more rows, and abbreviated variable names ¹​subdistrict,\n#   ²​vaccination_rate"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-morans-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#computing-local-morans-i",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "5.2 Computing local Moran’s I",
    "text": "5.2 Computing local Moran’s I\nNext, we will use local_moran() of the sfdep package to calculate local Moran’s I.\n\nset.seed(1234)\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(vaccination_rate,\n                                   nb,\n                                   wt,\n                                   nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualizing-p-value-of-local-morans-i",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualizing-p-value-of-local-morans-i",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "5.3 Visualizing p-value of local Moran’s I",
    "text": "5.3 Visualizing p-value of local Moran’s I\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\", \n          palette =\"-Reds\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, Inf)) +\n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#putting-it-all-together",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#putting-it-all-together",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "5.4 Putting it all together",
    "text": "5.4 Putting it all together\nAs you follow along, these are the 3 main steps to creating the plots required for this section. As mentioned above, we will combine these 3 sections into a single function to calculate the local Gi for each month. The code chunk below takes in input “mth” to filter vaccination to the respective month and calculate the weights and the local Moran’s I. ### Creating the local MI computation function\n\nlisa <- function(mth){\n  set.seed(1234)\n  month <- vaccination %>%\n    filter(date ==mth)\n  wm_q <- month %>%\n    mutate(nb = st_contiguity(geometry),\n           wt = st_weights(nb,\n                           style = \"W\"),\n           .before = 1)\n  result <- wm_q %>%\n    mutate(local_moran = local_moran(vaccination_rate,\n                                     nb,\n                                     wt,\n                                     nsim = 99),\n           .before = 1) %>% \n    unnest(local_moran)\n  return(result)\n}\n\nNow we will calculate the local Moran’s I for each month and place it into a list for easy referencing for the plots later.\n\ndate = c(\"2021-07-01\", \"2021-08-01\", \"2021-09-01\", \"2021-10-01\", \"2021-11-01\", \"2021-12-01\", \"2022-01-01\", \"2022-02-01\", \"2022-03-01\", \"2022-04-01\", \"2022-05-01\", \"2022-06-01\")\nlisa_LMI <- list()\nfor (i in 1:12){\n  lisa_LMI[[i]] <- lisa(date[i])\n}\n\nNow we have a list of dataframes with local Moran I computed. Note that lisa_LMI[[1]] refers to July 2021, in ascending order.\n\n5.4.1 Creating the Tmap function\n\ngraph_lisa <- function(x){\n  plot <- tm_shape(x) +\n    tm_fill(\"p_ii_sim\", \n            palette =\"-Reds\", \n            breaks=c(-Inf, 0.001, 0.01, 0.05, Inf)) +\n    tm_borders(alpha = 0.5) +\n    tm_layout(main.title = paste(\"p-value of local Moran's I\", \"(\",x$date[1],\")\"),\n              main.title.size = 0.8)\n  return(plot)\n}\n\n\ntmap_mode(\"plot\")\ntmap_arrange(graph_lisa(lisa_LMI[[1]]),\n             graph_lisa(lisa_LMI[[2]]),\n             graph_lisa(lisa_LMI[[3]]),\n             graph_lisa(lisa_LMI[[4]]),\n             graph_lisa(lisa_LMI[[5]]),\n             graph_lisa(lisa_LMI[[6]]),\n             ncol =2)\n\n\n\n\n\ntmap_arrange(graph_lisa(lisa_LMI[[7]]),\n             graph_lisa(lisa_LMI[[8]]),\n             graph_lisa(lisa_LMI[[9]]),\n             graph_lisa(lisa_LMI[[10]]),\n             graph_lisa(lisa_LMI[[11]]),\n             graph_lisa(lisa_LMI[[12]]),\n             ncol =2)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#statistical-conclusion-not-more-than-250words",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#statistical-conclusion-not-more-than-250words",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "5.5 Statistical Conclusion (Not more than 250words) :",
    "text": "5.5 Statistical Conclusion (Not more than 250words) :"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#creating-a-time-series-cube",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#creating-a-time-series-cube",
    "title": "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta",
    "section": "6.1 Creating a Time Series Cube",
    "text": "6.1 Creating a Time Series Cube\nThe code chunk below creates a spatio-temporal cube by using spacetime() from the sfdep package\n\nvaccination_rate_st<- spacetime(aspatial_data, \n                                geoDKI, \n                                .loc_col = \"subdistrict\",\n                                .time_col = \"date\")\n\n\nvaccination_rate_nb <- vaccination_rate_st %>%\n  activate(\"geometry\")\n  \nresult <- vaccination_rate_nb %>%\n  mutate(\n    nb = include_self(st_contiguity(geometry)),\n    wt = st_weights(nb)) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n\ngi_star <- vaccination_rate_nb %>%\n  group_by(as.numeric(date)) %>%\n  mutate(gi_star = local_gstar_perm(aspatial_data, \n                                    nb, \n                                    wt, \n                                    nsim = 99)) %>%\n  tidyr::unnest(gi_star)\n\n\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    aspatial_data, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\nHCSA"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "",
    "text": "Unlike the Hands-on Ex07, we will mainly use sfdep package for calculating the global and local measures. This is because spdep is going to be discontinued.\n\n\n\npacman::p_load(sf,sfdep,tmap,tidyverse)\n\n\n\n\n\nhunan <- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/junhaoteo/Documents/junhao2309/IS415/In-class_Ex/In-class_Ex07/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\n\n\nhunan_GDPPC <- left_join(hunan, hunan2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-contiguity-weights-queens-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-contiguity-weights-queens-method",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "2.1 Deriving contiguity weights: Queen’s method",
    "text": "2.1 Deriving contiguity weights: Queen’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-global-morans-i",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-global-morans-i",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "2.2 Computing Global Moran’s I",
    "text": "2.2 Computing Global Moran’s I\n\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morans-i-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morans-i-test",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "2.3 Performing Global Moran’s I Test",
    "text": "2.3 Performing Global Moran’s I Test\n\nglobal_moran_test(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morani-permutation-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morani-permutation-test",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "2.4 Performing Global Moran’I permutation test",
    "text": "2.4 Performing Global Moran’I permutation test\n\nset.seed(1234)\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-morans-i",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "2.5 Computing Local Moran’s I",
    "text": "2.5 Computing Local Moran’s I\n\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(GDPPC,\n                                   nb,\n                                   wt, \n                                   nsim =99),\n         .before = 1) %>%\n  unnest(local_moran)\nlisa\n\nSimple feature collection with 88 features and 20 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 21\n         ii        eii   var_ii    z_ii    p_ii p_ii_…¹ p_fol…² skewn…³ kurtosis\n      <dbl>      <dbl>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>    <dbl>\n 1 -0.00147  0.00177    4.18e-4 -0.158  0.874      0.82    0.41  -0.812  0.652  \n 2  0.0259   0.00641    1.05e-2  0.190  0.849      0.96    0.48  -1.09   1.89   \n 3 -0.0120  -0.0374     1.02e-1  0.0796 0.937      0.76    0.38   0.824  0.0461 \n 4  0.00102 -0.0000349  4.37e-6  0.506  0.613      0.64    0.32   1.04   1.61   \n 5  0.0148  -0.00340    1.65e-3  0.449  0.654      0.5     0.25   1.64   3.96   \n 6 -0.0388  -0.00339    5.45e-3 -0.480  0.631      0.82    0.41   0.614 -0.264  \n 7  3.37    -0.198      1.41e+0  3.00   0.00266    0.08    0.04   1.46   2.74   \n 8  1.56    -0.265      8.04e-1  2.04   0.0417     0.08    0.04   0.459 -0.519  \n 9  4.42     0.0450     1.79e+0  3.27   0.00108    0.02    0.01   0.746 -0.00582\n10 -0.399   -0.0505     8.59e-2 -1.19   0.234      0.28    0.14  -0.685  0.134  \n# … with 78 more rows, 12 more variables: mean <fct>, median <fct>,\n#   pysal <fct>, nb <nb>, wt <list>, NAME_2 <chr>, ID_3 <int>, NAME_3 <chr>,\n#   ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>, geometry <POLYGON [°]>, and\n#   abbreviated variable names ¹​p_ii_sim, ²​p_folded_sim, ³​skewness"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualizing-lisa",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualizing-lisa",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "2.6 Visualizing Lisa",
    "text": "2.6 Visualizing Lisa\n\n2.6.1 Visualize Local Moran’s I plot\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5)+\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\n\n2.6.2 p-value plot\n\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_fill(\"p_ii\") +\n  tm_borders(alpha = 0.5)+\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\nlisa_sig <- lisa %>%\n  filter(p_ii <0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-moransi",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-moransi",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "3.1 Computing local Moran’sI",
    "text": "3.1 Computing local Moran’sI\n\nHCSA <- wm_q %>%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim =99),\n    .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 17\n    gi_star   e_gi     var_gi  p_value p_sim p_fol…¹ skewn…² kurto…³ nb    wt   \n      <dbl>  <dbl>      <dbl>    <dbl> <dbl>   <dbl>   <dbl>   <dbl> <nb>  <lis>\n 1 -0.00567 0.0115 0.00000812  9.95e-1  0.82    0.41   1.03    1.23  <int> <dbl>\n 2 -0.235   0.0110 0.00000581  8.14e-1  1       0.5    0.912   1.05  <int> <dbl>\n 3  0.298   0.0114 0.00000776  7.65e-1  0.7     0.35   0.455  -0.732 <int> <dbl>\n 4  0.145   0.0121 0.0000111   8.84e-1  0.64    0.32   0.900   0.726 <int> <dbl>\n 5  0.356   0.0113 0.0000119   7.21e-1  0.64    0.32   1.08    1.31  <int> <dbl>\n 6 -0.480   0.0116 0.00000706  6.31e-1  0.82    0.41   0.364  -0.676 <int> <dbl>\n 7  3.66    0.0116 0.00000825  2.47e-4  0.02    0.01   0.909   0.664 <int> <dbl>\n 8  2.14    0.0116 0.00000714  3.26e-2  0.16    0.08   1.13    1.48  <int> <dbl>\n 9  4.55    0.0113 0.00000656  5.28e-6  0.02    0.01   1.36    4.14  <int> <dbl>\n10  1.61    0.0109 0.00000341  1.08e-1  0.18    0.09   0.269  -0.396 <int> <dbl>\n# … with 78 more rows, 7 more variables: NAME_2 <chr>, ID_3 <int>,\n#   NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>, and abbreviated variable names ¹​p_folded_sim,\n#   ²​skewness, ³​kurtosis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualizing-gi",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualizing-gi",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "3.2 Visualizing Gi*",
    "text": "3.2 Visualizing Gi*\n\ntmap_mode(\"view\")\ntm_shape(HCSA)+\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha=0.5)+\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\npacman::p_load(plotly)\n\n\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#creating-a-time-series-cube",
    "title": "In-class Exercise 7: Global and Local Measures",
    "section": "3.3 Creating a Time Series Cube",
    "text": "3.3 Creating a Time Series Cube\nThe code chunk below creates a spatio-temporal cube by using spacetime() from the sfdep packagePC\n\nGDPPC_st <- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\n\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>%\n  mutate(\n    nb = include_self(st_contiguity(geometry)),\n    wt = st_weights(nb)) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n\n3.3.1 Computing Gi\n\ngi_star <- GDPPC_nb %>%\n  group_by(Year) %>%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99)) %>%\n  tidyr::unnest(gi_star)\n\n\n\n3.3.2 Performing Emerging Hotspot analysis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "pacman::p_load(sf, sfdep, tidyverse, tmap)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "title": "In-class Exercise 6",
    "section": "2.1 Importing Geospatial data",
    "text": "2.1 Importing Geospatial data\n\nhunan <- st_read(dsn = \"data/geospatial/\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/junhaoteo/Documents/junhao2309/IS415/In-class_Ex/In-class_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-aspatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-aspatial-data",
    "title": "In-class Exercise 6",
    "section": "2.2 Importing Aspatial data",
    "text": "2.2 Importing Aspatial data\n\nhunan_2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\n\nhunan_GDPPC <- dplyr::left_join(hunan, hunan_2012) %>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#visualize-the-data-on-a-choropleth-map",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#visualize-the-data-on-a-choropleth-map",
    "title": "In-class Exercise 6",
    "section": "2.3 Visualize the data on a Choropleth Map",
    "text": "2.3 Visualize the data on a Choropleth Map\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC) +\n  tm_fill(\"GDPPC\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by district\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha =0.5) +\n  tm_compass(type = \"8star\", size =2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-neighbours-method",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-neighbours-method",
    "title": "In-class Exercise 6",
    "section": "3.1 Contiguity neighbours method",
    "text": "3.1 Contiguity neighbours method\nIn the code chunk below, st_contiguity() is used to derive a contiguity neighbour list by using Queen’s method. By default, st_contiguity() uses queen = TRUE.\n\ncn_queen <- hunan_GDPPC %>%\n  mutate(nb= st_contiguity(geometry),\n         .before = 1)\n\nThe code chunk below uses st_contiguity() with queen = FALSE. This makes the contiguity neighbor list using the Rook’s method.\n\ncn_rook <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, \n                            queen = FALSE),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-contiguity-weights",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#computing-contiguity-weights",
    "title": "In-class Exercise 6",
    "section": "3.2 Computing contiguity weights",
    "text": "3.2 Computing contiguity weights\n\n3.2.1 Queen’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\n\n3.2.2 Rook’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         queen = FALSE,\n         wt = st_weights(nb),\n         .before = 1)"
  }
]