---
title: "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta"
date: "13 February 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# Context

Since the outbreak of COVID-19, many countries have rushed to create a vaccine and ensure its population is well immunized against this novel coronavirus. On 13 January 2021, the mass immunisation program commenced and since then Indonesia ranks third in Asia and fifth in the world in terms of total doses given.

In this take-home assignment, we will be exploring vaccination rates in DKI Jarkarta, identifying sub-districts with relatively higher number of vaccination rate and how they changed over time.

The tasks given to us is as follows:

**Choropleth Mapping and Analysis**

-   Compute the monthly vaccination rate from July 2021 to June 2022 at sub-district (also known as kelurahan in Bahasa Indonesia) level,

-   Prepare the monthly vaccination rate maps by using appropriate tmap functions,

-   Describe the spatial patterns revealed by the choropleth maps (not more than 200 words).

**Local Gi\* Analysis**

With reference to the vaccination rate maps prepared in ESDA:

-   Compute local Gi\* values of the monthly vaccination rate,

-   Display the Gi\* maps of the monthly vaccination rate. The maps should only display the significant (i.e. p-value \< 0.05)

-   With reference to the analysis results, draw statistical conclusions (not more than 250 words).

**Emerging Hot Spot Analysis(EHSA)**

With reference to the local Gi\* values of the vaccination rate maps prepared in the previous section:

-   Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values,

-   Select three sub-districts and describe the temporal trends revealed (not more than 250 words), and

-   Prepared a EHSA map of the Gi\* values of vaccination rate. The maps should only display the significant (i.e. p-value \< 0.05).

-   With reference to the EHSA map prepared, describe the spatial patterns revelaed. (not more than 250 words).

Throughout this page, each step will be explained and guided so that you can follow along.

# The Set Up

## Packages Used

The R packages used for this analysis are:

-   sf

-   tidyverse

-   spatstat

-   tmap

-   sfdep

-   maptools

-   readxl

The code chunk below checks whether the packages have been installed, if not it will automatically install them and load the packages into Rstudio.

```{r}
pacman::p_load(sf, raster, spatstat, tmap, tidyverse, sfdep, maptools, readxl, spdep)
```

## The Data

| Type       | Name                                                                                                                   | Format    | Description                                                                   |
|------------------|--------------------|------------------|------------------|
| Geospatial | [Batas Desa Provinsi DKI Jakarta](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html) | shapefile | Sub-districts in DKI Jakarta                                                  |
| Aspatial   | [Riwayat File Vaksinasi DKI Jakarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/)            | .xlsx     | Sub-district level data of vaccination numbers between July 2021 to June 2022 |

-   Geospatial Data

The link under Geospatial Data above brings you to a page where there are many download links sorted by province. Ensure that you are using **Shapefile (SHP) Batas Desa Provinsi DKI Jakarta.**

-   Aspatial Data

The link under Aspatial Data above brings you to a page where there are two types of data files you can use. Please choose **Data Vaksinasi Berbasis Kelurahan dan Kecamatan** and download a total of 12 files beginning July 2021 to June 2022.

Do note that we will be using the beginning of each month for our download.

# Data Wrangling

## Geospatial Data

### Import Geospatial Data

```{r}
geoDKI <- st_read(dsn = "data/geospatial",
                    layer = "BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA")
```

From the output above, we can see that the data set has a geometry type, Multipolygon, and has 269 features and 161 fields.

### Check for invalid geometries

Before we begin, we should check whether there are any invalid geometries by using the code chunk below:

```{r}
st_is_valid(geoDKI)
```

st_is_valid() from the sf package helps to check whether a geometry is valid. From the output, there are no invalid geometries.

### Check for Missing values

The code chunk below uses is.na() from base R checks whether the data set has NA values. which() from base R takes the indices of these values and lastly length() helps us calculate the length of the data objects.

```{r}
length(which(is.na(geoDKI) == TRUE))
```

In the above output, there are 14 NA values within the jakarta data set.

To remove them, we can simply use na.exclude to delete the rows with NA values

```{r}
geoDKI <- na.omit(geoDKI)
```

We can run the same code to see whether all NA values have been removed.

```{r}
length(which(is.na(geoDKI) == TRUE))
```

Nice! All NA values have been removed.

### Check Coordinate System

As different countries use different projection systems, we need to first check the CRS of jakarta.

The code chunk below uses st_crs() from the sf package:

```{r}
st_crs(geoDKI)
```

We notice that jakarta is using EPSG::4326 which is the wrong projection coordinate system. DKI Jakarta uses the DGN95, the 'Datum Geodesi Nasional 1995', EPSG::23878

We can transform the crs by using st_transform() from the sf package:

```{r}
geoDKI <- geoDKI %>%
  st_transform(crs = 23878)
```

```{r}
st_crs(geoDKI)
```

From the output above, we can see that the CRS has been properly assigned.

### Removing Outer Islands

Let us visualise the geographical polygons.

```{r}
qtm(geoDKI)
```

We can see from the output that jakarta includes both the mainland and the outer islands. Our study area focuses only on the mainland and thus we need to remove them.

```{r, eval = FALSE}
View(geoDKI)
```

Before we continue further, we need to understand how DKI Jakarta geographical regions are segmented. The code chunk above lets you view the entire dataset. Let us understand the key variables below:

With the help of uncle google, we will translate the names.

| Name       | Translation  |
|------------|--------------|
| KODE_DESA  | Village Code |
| DESA       | Village      |
| PROVINSI   | Province     |
| KAB_KOTA   | City         |
| KECAMATAN  | District     |
| DESA_KELUR | Sub-District |

KAB_KOTA would be the most logical choice in isolating out the outer islands.

The code chunk below helps to output uniques values in KAB_KOTA field.

```{r}
unique(geoDKI$KAB_KOTA)
```

The output above shows that there are 6 major cities in DKI Jakarta.

The codechunk below will visualize the data with respect to the 6 major cities. We can then see which city isolates out the outer islands.

```{r}
tmap_mode("plot")
tm_shape(geoDKI) +
  tm_polygons("KAB_KOTA")
```

From the visualization above, we can see that KEPULAUAN SERIBU is not part of the mainland. We can then use filter() from dplyr package to remove the outer islands.

```{r}
geoDKI <- filter(geoDKI, KAB_KOTA !="KEPULAUAN SERIBU")
```

```{r}
qtm(geoDKI)
```

Now we can see that our shapefile only contains the mainland, which is our study area.

Now, before we move on, geoDKI has alot of columns, we will select those that are relevant to our analysis:

```{r}
geoDKI <- geoDKI %>%
  select(2,5,6,7,8)
```

## Aspatial Data

### Import Aspatial Data

Before we import the data in, the file names are rather long. First, go to your data folder and change the aspatial data file names to Y-M format. It would look like this:

![](images/image-1137647241.png){fig-align="center" width="488"}

There are a total of 12 excel files we need to load into Rstudio. To read the files more efficiently, we will use the "for loop" function to read all the excel files into a data frame by using the read_excel() from the readxl package.

```{r}
# Set the working directory to the folder containing the Excel files
setwd("data/aspatial/")
# Get a list of all Excel files in the directory
aspatial_data <- list.files(pattern = ".xlsx")

# Loop through the files and read each one into a data frame
for (i in aspatial_data) {
  assign(gsub(".xlsx", "", i), read_excel(i))
}
```

### Columns of interest and its translation

In the aspatial data set, what we want is the total vaccination and not vaccinated numbers, along with these 4 regional classification columns.

```{r}
names(`2022-6`)
```

| Name                        | Translation       |
|-----------------------------|-------------------|
| KODE KELURAHAN              | Village Code      |
| WILAYAH KOTA                | City Region       |
| KECAMATAN                   | Sub-District      |
| KELURAHAN                   | Ward              |
| TOTAL VAKSIN\\r\\nDIBERIKAN | Total Vaccination |
| BELUM VAKSIN                | Not Vaccinated    |

### Mutate Aspatial Data

#### Mutating using for loop

As there are 12 data sets, we will use the for loop that mutate, rename and select the fields that we want. The code chunk below does the following:

1.  Renames KODE KELURAHAN, WILAYAH KOTA, KECAMATAN, KELURAHAN, TOTAL VAKSIN\\r\\nDIBERIKAN and BELUM VAKSIN to village_code, city_region, subdistrict, ward, total_vaccination and not_vaccinated respectively by using rename() from the dplyr package
2.  Selects the renamed columns by using select() from the dplyr package
3.  Adds a date column by using mutate() from the dplyr package

All the mutated aspatial data frames are then placed into a list

```{r}
list_mth<- list(`2021-7`,`2021-8`,`2021-9`,`2021-10`,`2021-11`,`2021-12`,`2022-1`,`2022-2`,`2022-3`,`2022-4`,`2022-5`,`2022-6`)

date <- c("July 2021", "August 2021", "September 2021", "October 2021", "November 2021", "December 2021", "January 2022", "February 2022", "March 2022", "April 2022", "May 2022", "June 2022")

lists <- list()
for (i in c(1:12)){
  lists[[i]]<- list_mth[[i]] %>% 
    rename(village_code=`KODE KELURAHAN`, 
           city_region =`WILAYAH KOTA`, 
           subdistrict=`KECAMATAN`, 
           ward=`KELURAHAN`, 
           total_vaccination= `TOTAL VAKSIN\r\nDIBERIKAN`, 
           not_vaccinated =`BELUM VAKSIN`) %>% 
  select(village_code, city_region, subdistrict, not_vaccinated ,total_vaccination) %>%
    mutate(date = date[i], 
           .before=1)
}
```

#### Combine into a single dataframe from a list of dataframes

Afterwhich, we can use Reduce() and rbind from base R to join all dataframes in the lists as one dataframe.

The code chunk below does this:

```{r}
aspatial_data <- Reduce(rbind, lists)
glimpse(aspatial_data)
```

We can see from the output that we have the columns that we want in its new name and having 3216 rows.

From the glimpse output, we can see that there are NA values inside the dataframe. If you View the original individual files, you will notice that there will be a row that calculates the total of a respective column.

#### Final steps to take

So these are the steps to take,

1.  Remove the NA rows in the dataframe
2.  Filter out the outer islands
    -   You will notice from the output of the code chunk below that outer islands is categorised as KAB.ADM.KEP.SERIBU

```{r}
unique(aspatial_data$city_region)
```

3.  Add in total population and vaccination rate columns
    -   Formula:

The code chunk below does this:

```{r}
aspatial_data <- aspatial_data %>%
  na.exclude() %>%
  filter(city_region != "KAB.ADM.KEP.SERIBU") %>%
  mutate(total_population = total_vaccination + not_vaccinated, vaccination_rate = total_vaccination/total_population)
```

## Combining Geospatial and Aspatial together

Do note that the names for aspatial_data and geoDKI are of different names. Ensure that when using left_join() from the dplyr package, we insert the argument by = c(). This will join using village_code

```{r}
vaccination <- left_join(aspatial_data, geoDKI, 
                         by = c("village_code" = "KODE_DESA"))
```

```{r}
vaccination <- st_as_sf(vaccination) %>%
  mutate(date = as.factor(date))
```

# Choropleth Mapping and Analysis

## Visualizing the data

### R Shiny

Something extra to this TakeHome Assignment will be the use of the ShinyApp. This is a short introduction as to how Rshiny works:

1.  Define the UI:
    -   You will have an input and in this case, we will use selectInput("dates", "Pick a month", date, selected = "July 2021",multiple = FALSE).

        -   "dates": This is the variable name to call into the output portion in the server

        -   "Pick a month": This is a text under the user interface to ask the user to pick a choice

        -   date: This is the vector of choices that they can pick from.

        -   selected = "July 2021" : This sets the choice "July 2021" as the default when starting up the app

        -   multiple = FALSE : Prevents the user from picking multiple options and can only choose 1
2.  Define Server:
    -   This is where tmap is used and calls upon the variable name defined in UI which is "dates".

```{r, eval = FALSE}
library(shiny)

date <- c("July 2021", "August 2021", "September 2021", "October 2021", "November 2021", "December 2021", "January 2022", "February 2022", "March 2022", "April 2022", "May 2022", "June 2022")
# Define the UI
ui <- fluidPage(
  selectInput("dates", "Pick a month",
              date, selected = "July 2021",
              multiple = FALSE),
  
  tmapOutput("my_map")
)

# Define the server
server <- function(input, output) {
  # Render the tmap in the output element
  output$my_map <- renderTmap({
    a <- vaccination |>
      filter(date == input$dates)

    tm_shape(a) +
  tm_fill("vaccination_rate",
          style = "quantile",
          palette ="Blues")
  })
}

# Run the app
shinyApp(ui, server)
```

Refer to visual plot : [ShinyApp](https://junhaoteo.shinyapps.io/Take-Home_Ex02/)

Note: There are many ways to create and design the shiny app, under the user interface. One example is using a sliderInput() to let the user their zoom level. This can be found under R shiny documentation.

### Tmap Visualization

Considering we have 12 months of Tmap visualization to do, it would be better to create a tmap function.

The code chunk below first filters out vaccination dataframe into their respective months and then inputs the filtered dataframe into the tm_shape().

```{r}
graphing <- function(x){
  a <- vaccination %>%
    filter(date == x)
  tm_shape(a) +
  tm_fill("vaccination_rate",
          n = 6,
          style = "quantile",
          palette = "Blues",
          title = "Vaccination Rate") +
  tm_layout(main.title = paste(x),
            main.title.position = "left",
            legend.height = 0.8, 
            legend.width = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_grid(alpha =0.2)
}
```

We will split the plots into 2 code chunks to reduce the number of graphs in a single output for a clearer view.

```{r}
tmap_mode("plot")
tmap_arrange(graphing("July 2021"),
             graphing("August 2021"),
             graphing("September 2021"),
             graphing("October 2021"),
             graphing("November 2021"),
             graphing("December 2021"),
             ncol = 2)
```

```{r}
tmap_arrange(graphing("January 2022"),
             graphing("February 2022"),
             graphing("March 2022"),
             graphing("April 2022"),
             graphing("May 2022"),
             graphing("June 2022"),
             ncol = 2)
```

To visualize the data, we can just create a gif, compiled by all the plots made above.

![](images/7bmx3b.gif){fig-align="center"}

Likewise, this can be done on Rshiny app but this will be covered on a later date when I have attended the Rshiny workshop. :)

## Spatial Patterns observed (200words)

# Local Gi\* Analysis

To bring you back, here is the task assigned in this section:

-   Compute local Gi\* values of the monthly vaccination rate,

-   Display the Gi\* maps of the monthly vaccination rate. The maps should only display the significant (i.e. p-value \< 0.05)

-   With reference to the analysis results, draw statistical conclusions (not more than 250 words)

## Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct the spatial weights of the study area.

Spatial weights: Used to define the neighbourhood relationships between geographical units in the study area.

By using the poly2nb() of spdep package, we can compute the contiguity weight matrices for the study area.

As we are dealing with 12 different months of vaccination rates, we will have to filter the dataframe to their respective months and calculate their respective weights. Here, we will be using the ROOK mode and thus the argument: queen =FALSE. The code chunk below is a filters to the selected month and then calculate their weights by using poly2nb() of the spdep package:

```{r}
month <- vaccination %>%
    filter(date == "July 2021")
wm <-poly2nb(month,
             queen = TRUE)
summary(wm)
```

The summary report above shows that there are 261 area units in DKI Jakarta and the most connected area unit has 11 neighbours.

## Row-standardised weights matrix

Moving on, we will need to assign weights to each neighbouring polygon.

```{r}
rswm <- nb2listw(wm,
                 style = "W",
                   zero.policy = TRUE)
rswm
```

## Moran I Test

To run all 12 months local Gi, we will create a function calculates the weights, assignes them to each neighbouring polygon and then to calculate the statistical values. When calculating each month, we want to ensure that the dataframe used is the correct on and thus the reason why we put them together. The code chunk below features a function that takes the month as an input and returns the Moran's I test.

```{r}
localmoran_test <- function(mth){
  month <- vaccination %>%
    filter(date == mth)
  wm_q <- poly2nb(month,
                 queen = TRUE)
  rswm_q <- nb2listw(wm_q,
                     style = "W",
                     zero.policy = TRUE)
  fips <- order(month$vaccination_rate)
  localMI <- localmoran(month$vaccination_rate, rswm_q)

  return(localMI)
  }
```

The code chunk below applies localmoran_test() to a list of dates and output the data into a list. Do note that date is a list containing "July 2021", "August 2021", ... , "June 2020"

```{r}
localmoran_test_stat <- lapply(date, FUN = localmoran_test)
head(localmoran_test_stat[[1]], 6)
```

The output of the code chunk below follows the same sequence as date where localmoran_test_stat\[\[1\]\] refers to "July 2021" and localmoran_test_stat\[\[12\]\] refers to "June 2022".

The code chunks below creates a function that binds the filtered dataframe and the localmoran_test_stat together and loops it into a list called vac.localMI.

```{r}
localMI<- function(mth,x){
  month <- vaccination %>%
    filter(date == mth)
  vac_mth.local.MI <- cbind(month, localmoran_test_stat[[x]]) %>%
    rename(Pr.Ii=`Pr.z....E.Ii..`)
  return(vac_mth.local.MI)
}
```

```{r}
vac.localMI <- list()
for (i in 1:12){
  vac.localMI[[i]] <- localMI(date[i], i)
}
```

We can then visualize the date below.

```{r}
tmap_mode("plot")
localMI_Map <- function(MI){
  tm_shape(MI) +
  tm_fill(col = "Pr.Ii",
          breaks=c(-Inf, 0.001, 0.01, 0.05, Inf),
          palette = "-Blues",
          title = "local moran p-value") +
  tm_borders(alpha = 0.5)
}
```

```{r}
tmap_arrange(localMI_Map(vac.localMI[[1]]),
             localMI_Map(vac.localMI[[2]]),
             localMI_Map(vac.localMI[[3]]),
             localMI_Map(vac.localMI[[4]]),
             localMI_Map(vac.localMI[[5]]),
             localMI_Map(vac.localMI[[6]]),
             ncol = 2)
```

### Statistical Conclusion (Not more than 250words) :

###  

```{r}

```
