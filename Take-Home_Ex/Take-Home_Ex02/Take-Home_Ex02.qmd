---
title: "Take-Home Exercise 2: Spatio-temporal analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jarkarta"
date: "13 February 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# Context

Since the outbreak of COVID-19, many countries have rushed to create a vaccine and ensure its population is well immunized against this novel coronavirus. On 13 January 2021, the mass immunisation program commenced and since then Indonesia ranks third in Asia and fifth in the world in terms of total doses given.

In this take-home assignment, we will be exploring vaccination rates in DKI Jarkarta, identifying sub-districts with relatively higher number of vaccination rate and how they changed over time.

The tasks given to us is as follows:

**Choropleth Mapping and Analysis**

-   Compute the monthly vaccination rate from July 2021 to June 2022 at sub-district (also known as kelurahan in Bahasa Indonesia) level,

-   Prepare the monthly vaccination rate maps by using appropriate tmap functions,

-   Describe the spatial patterns revealed by the choropleth maps (not more than 200 words).

**Local Gi\* Analysis**

With reference to the vaccination rate maps prepared in ESDA:

-   Compute local Gi\* values of the monthly vaccination rate,

-   Display the Gi\* maps of the monthly vaccination rate. The maps should only display the significant (i.e. p-value \< 0.05)

-   With reference to the analysis results, draw statistical conclusions (not more than 250 words).

**Emerging Hot Spot Analysis(EHSA)**

With reference to the local Gi\* values of the vaccination rate maps prepared in the previous section:

-   Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values,

-   Select three sub-districts and describe the temporal trends revealed (not more than 250 words), and

-   Prepared a EHSA map of the Gi\* values of vaccination rate. The maps should only display the significant (i.e. p-value \< 0.05).

-   With reference to the EHSA map prepared, describe the spatial patterns revelaed. (not more than 250 words).

Throughout this page, each step will be explained and guided so that you can follow along.

# The Set Up

## Packages Used

The R packages used for this analysis are:

-   sf

-   tidyverse

-   spatstat

-   tmap

-   sfdep

-   maptools

-   readxl

The code chunk below checks whether the packages have been installed, if not it will automatically install them and load the packages into Rstudio.

```{r}
pacman::p_load(sf, raster, spatstat, tmap, tidyverse, sfdep, maptools, readxl, plotly)
```

## The Data

| Type       | Name                                                                                                                   | Format    | Description                                                                   |
|------------|-------------------------------|------------|-------------------|
| Geospatial | [Batas Desa Provinsi DKI Jakarta](https://www.indonesia-geospasial.com/2020/04/download-shapefile-shp-batas-desa.html) | shapefile | Sub-districts in DKI Jakarta                                                  |
| Aspatial   | [Riwayat File Vaksinasi DKI Jakarta](https://riwayat-file-vaksinasi-dki-jakarta-jakartagis.hub.arcgis.com/)            | .xlsx     | Sub-district level data of vaccination numbers between July 2021 to June 2022 |

-   Geospatial Data

The link under Geospatial Data above brings you to a page where there are many download links sorted by province. Ensure that you are using **Shapefile (SHP) Batas Desa Provinsi DKI Jakarta.**

-   Aspatial Data

The link under Aspatial Data above brings you to a page where there are two types of data files you can use. Please choose **Data Vaksinasi Berbasis Kelurahan dan Kecamatan** and download a total of 12 files beginning July 2021 to June 2022.

Do note that we will be using the beginning of each month for our download.

# Data Wrangling

## Geospatial Data

### Import Geospatial Data

```{r}
geoDKI <- st_read(dsn = "data/geospatial",
                    layer = "BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA")
```

From the output above, we can see that the data set has a geometry type, Multipolygon, and has 269 features and 161 fields.

### Check for invalid geometries

Before we begin, we should check whether there are any invalid geometries by using the code chunk below:

```{r}
st_is_valid(geoDKI)
```

st_is_valid() from the sf package helps to check whether a geometry is valid. From the output, there are no invalid geometries.

### Check for Missing values

The code chunk below uses is.na() from base R checks whether the data set has NA values. which() from base R takes the indices of these values and lastly length() helps us calculate the length of the data objects.

```{r}
length(which(is.na(geoDKI) == TRUE))
```

In the above output, there are 14 NA values within the jakarta data set.

We will just hold onto these 14 NA values and move on first.

### Check Coordinate System

As different countries use different projection systems, we need to first check the CRS of jakarta.

The code chunk below uses st_crs() from the sf package:

```{r}
st_crs(geoDKI)
```

We notice that jakarta is using EPSG::4326 which is the wrong projection coordinate system. DKI Jakarta uses the DGN95, the 'Datum Geodesi Nasional 1995', EPSG::23878

We can transform the crs by using st_transform() from the sf package:

```{r}
geoDKI <- geoDKI %>%
  st_transform(crs = 23878)
```

```{r}
st_crs(geoDKI)
```

From the output above, we can see that the CRS has been properly assigned.

### Removing Outer Islands

Let us visualise the geographical polygons.

```{r}
qtm(geoDKI)
```

We can see from the output that jakarta includes both the mainland and the outer islands. Our study area focuses only on the mainland and thus we need to remove them.

```{r, eval = FALSE}
View(geoDKI)
```

Before we continue further, we need to understand how DKI Jakarta geographical regions are segmented. The code chunk above lets you view the entire dataset. Let us understand the key variables below:

With the help of uncle google, we will translate the names.

| Name      | Translation                       |
|-----------|-----------------------------------|
| KODE_DESA | Village Code (Sub-District Codes) |
| DESA      | Village                           |
| PROVINSI  | Province                          |
| KAB_KOTA  | City                              |
| KECAMATAN | Sub-District                      |

KAB_KOTA would be the most logical choice in isolating out the outer islands. This will be shown in the plots later.

The code chunk below helps to output unique values in KAB_KOTA field.

```{r}
unique(geoDKI$KAB_KOTA)
```

The output above shows that there are 6 major cities in DKI Jakarta, ignoring the NA value.

The codechunk below will visualize the data with respect to the 6 major cities. We can then see which city isolates out the outer islands.

```{r}
tmap_mode("view")
tm_shape(geoDKI) +
  tm_polygons("KAB_KOTA")
```

#### Dealing with NA values

As seen in the above study area plot, the NA values in geoDKI pertains to the information of small areas that is shaded white.

By viewing geoDKI, row 243 and 244 is where all the NA resides at. From checking the area bounds online, the white sub-districts pertains to city region, JAKARTA UTARA. As we could not find the KODE DESA (village code), we will just assign unique values: 3188888801 and 3188888802 for now.

This ensures completeness in our geographical plots later on.

```{r}
geoDKI$KAB_KOTA[243]<-"JAKARTA UTARA"
geoDKI$KAB_KOTA[244]<-"JAKARTA UTARA"

geoDKI$KODE_DESA[243]<-"3188888801"
geoDKI$KODE_DESA[244]<-"3188888802"
```

#### Filtering out Outer Islands

From the visualization above, we can see that KEPULAUAN SERIBU is not part of the mainland. We can then use filter() from dplyr package to remove the outer islands.

```{r}
geoDKI <- filter(geoDKI, KAB_KOTA !="KEPULAUAN SERIBU")
```

```{r}
tmap_mode("plot")
tm_shape(geoDKI) + 
  tm_polygons("KAB_KOTA")
```

Now, before we move on further, geoDKI has alot of columns. Since we are only interested in the subdistrict level, we will select KODE_DESA and rename it to village_code.

Note: village_code is also known as the subdistrict code.

```{r}
geoDKI <- geoDKI %>%
  select(2, "geometry") %>%
  rename(village_code = `KODE_DESA`)
```

## Aspatial Data

### Import Aspatial Data

Before we import the data in, the file names are rather long. First, go to your data folder and change the aspatial data file names to Y-M format. It would look like this:

![](images/image-1137647241.png){fig-align="center" width="488"}

There are a total of 12 excel files we need to load into Rstudio. To read the files more efficiently, we will use the "for loop" function to read all the excel files into a data frame by using the read_excel() from the readxl package.

```{r}
# Set the working directory to the folder containing the Excel files
setwd("data/aspatial/")
# Get a list of all Excel files in the directory
aspatial_data <- list.files(pattern = ".xlsx")

# Loop through the files and read each one into a data frame
for (i in aspatial_data) {
  assign(gsub(".xlsx", "", i), read_excel(i))
}
```

### Columns of interest and its translation

In the aspatial data set, what we want is the total vaccination and not vaccinated numbers, along with these 4 regional classification columns.

```{r}
names(`2022-6`)
```

| Name           | Translation    |
|----------------|----------------|
| KODE KELURAHAN | Village Code   |
| WILAYAH KOTA   | City Region    |
| SASARAN        | Vaccinated     |
| BELUM VAKSIN   | Not Vaccinated |

### Mutate Aspatial Data

#### Mutating using for loop

As there are 12 data sets, we will use the for loop that mutate, rename and select the fields that we want. The code chunk below does the following:

1.  Renames KODE KELURAHAN, WILAYAH KOTA, SASARAN and BELUM VAKSIN to village_code, city_region, vaccinated and not_vaccinated respectively by using rename() from the dplyr package
2.  Selects the renamed columns by using select() from the dplyr package
3.  Adds a date column by using mutate() from the dplyr package

All the mutated aspatial data frames are then placed into a list

```{r}
list_mth<- list(`2021-7`,`2021-8`,`2021-9`,`2021-10`,`2021-11`,`2021-12`,`2022-1`,`2022-2`,`2022-3`,`2022-4`,`2022-5`,`2022-6`)

date <- c("2021-07-01", "2021-08-01", "2021-09-01", "2021-10-01", "2021-11-01", "2021-12-01",
          "2022-01-01", "2022-02-01", "2022-03-01","2022-04-01", "2022-05-01", "2022-06-01")

lists <- list()
for (i in c(1:12)){
  lists[[i]]<- list_mth[[i]] %>% 
    rename(village_code=`KODE KELURAHAN`,
           city_region =`WILAYAH KOTA`,
           vaccinated= `SASARAN`, 
           not_vaccinated =`BELUM VAKSIN`) %>% 
  select(village_code,city_region, not_vaccinated ,vaccinated) %>%
    mutate(date = as.Date(date[i]), 
           .before=1)
}
```

#### Combine into a single dataframe from a list of dataframes

Afterwhich, we can use Reduce() and rbind from base R to join all dataframes in the lists as one dataframe.

The code chunk below does this:

```{r}
aspatial_data <- Reduce(rbind, lists)
glimpse(aspatial_data)
```

We can see from the output that we have the columns that we want in its new name and having 3216 rows.

From the glimpse output, we can see that there are NA values inside the dataframe. If you View the original individual files, you will notice that there will be a row that calculates the total of a respective column and that row contains NA values.

#### Final steps to take

So these are the steps to take,

1.  Remove the NA rows in the dataframe
2.  Filter out the outer islands
    -   You will notice from the output of the code chunk below that outer islands is categorised as KAB.ADM.KEP.SERIBU

```{r}
unique(aspatial_data$city_region)
```

3.  Add in vaccination rate column
    -   Formula:

The code chunk below does this:

```{r}
aspatial_data <- aspatial_data %>%
  na.exclude() %>%
  filter(city_region != "KAB.ADM.KEP.SERIBU") %>% 
  mutate(total_population = vaccinated + not_vaccinated, 
         vaccination_rate = as.numeric(vaccinated/total_population)) %>%
  select(date, village_code, vaccination_rate)
```

4.  Add in village code: 3188888801 and 3188888802

Recall that there are two polygons that held missing values.

```{r}
setdiff(geoDKI$village_code, aspatial_data$village_code)
```

We notice that in the aspatial data, no information were collected for these two sub-districts. Hence, we have to add in these two subdistricts so that both dataframes will match when it is joint later on.

Note: Each month must have one observation, vaccination rate for the added rows will equal 0.

```{r}
aspatial_data <- rbind(aspatial_data, c("2021-07-01", 3188888801,NA),
                       c("2021-08-01", 3188888801,NA),
                       c("2021-09-01", 3188888801,NA),
                       c("2021-10-01", 3188888801,NA),
                       c("2021-11-01", 3188888801,NA),
                       c("2021-12-01", 3188888801,NA),
                       c("2022-01-01", 3188888801,NA),
                       c("2022-02-01", 3188888801,NA),
                       c("2022-03-01", 3188888801,NA),
                       c("2022-04-01", 3188888801,NA),
                       c("2022-05-01", 3188888801,NA),
                       c("2022-06-01", 3188888801,NA),
                       c("2021-07-01", 3188888802,NA),
                       c("2021-08-01", 3188888802,NA),
                       c("2021-09-01", 3188888802,NA),
                       c("2021-10-01", 3188888802,NA),
                       c("2021-11-01", 3188888802,NA),
                       c("2021-12-01", 3188888802,NA),
                       c("2022-01-01", 3188888802,NA),
                       c("2022-02-01", 3188888802,NA),
                       c("2022-03-01", 3188888802,NA),
                       c("2022-04-01", 3188888802,NA),
                       c("2022-05-01", 3188888802,NA),
                       c("2022-06-01", 3188888802,NA))
```

Both aspatial_data and geoDKI have the same number of unique village code.\
The code chunk below joins them together by their village code, sets vaccination_rate as numeric and excludes the NA values in the joined dataframe.

```{r}
vaccination <- left_join(aspatial_data, geoDKI, 
                         by = c("village_code")) %>%
  mutate(vaccination_rate = as.numeric(vaccination_rate)) %>%
  na.exclude()
```

```{r}
vaccination <- st_as_sf(vaccination)
```

# Choropleth Mapping and Analysis

## Visualizing the data

### iR Shiny

Something extra to this TakeHome Assignment will be the use of the ShinyApp. This is a short introduction as to how Rshiny works:

1.  Define the UI:
    -   You will have an input and in this case, we will use selectInput("dates", "Pick a month", date, selected = "July 2021",multiple = FALSE).

        -   "dates": This is the variable name to call into the output portion in the server

        -   "Pick a month": This is a text under the user interface to ask the user to pick a choice

        -   date: This is the vector of choices that they can pick from.

        -   selected = "July 2021" : This sets the choice "July 2021" as the default when starting up the app

        -   multiple = FALSE : Prevents the user from picking multiple options and can only choose 1
2.  Define Server:
    -   This is where tmap is used and calls upon the variable name defined in UI which is "dates".

```{r, eval = FALSE}
library(shiny)

date <- c("2021-07-01", "2021-08-01", "2021-09-01", "2021-10-01", "2021-11-01", "2021-12-01", "2022-01-01", "2022-02-01", "2022-03-01", "2022-04-01", "2022-05-01", "2022-06-01")
ui <- fluidPage(
  selectInput("dates", "Pick a date",
              date, selected = "2021-07-01",
              multiple = FALSE),

  tmapOutput("my_map")
)

# Define the server
server <- function(input, output) {
  # Render the tmap in the output element
  output$my_map <- renderTmap({
    a <- vaccination |>
      filter(date == input$dates)
    
    tm_shape(a) +
      tm_fill("vaccination_rate",
              n = 6,
              style = "quantile",
              palette = "Blues",
              title = "Vaccination Rate") +
      tm_layout(main.title = paste(input$dates),
                main.title.position = "left",
                legend.height = 0.8, 
                legend.width = 0.8,
                frame = TRUE) +
      tm_borders(alpha = 0.5) +
      tm_grid(alpha =0.2)
  })
}

# Run the app
shinyApp(ui, server)

```

Refer to visual plot : [ShinyApp](https://junhaoteo.shinyapps.io/Take-Home_Ex02/)

Note: There are many ways to create and design the shiny app, under the user interface. One example is using a sliderInput() to let the user their zoom level. This can be found under R shiny documentation.

### Tmap Visualization

Considering we have 12 months of Tmap visualization to do, it would be better to create a tmap function.

The code chunk below first filters out vaccination dataframe into their respective months and then inputs the filtered dataframe into the tm_shape().

```{r}
graphing <- function(x){
  a <- vaccination %>%
    filter(date == x)
  tm_shape(a) +
  tm_fill("vaccination_rate",
          n=10,
          style = "quantile",
          palette = "Blues",
          title = "Vaccination Rate") +
  tm_layout(main.title = paste(x),
            main.title.position = "left",
            legend.height = 0.8, 
            legend.width = 0.8,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_grid(alpha =0.2)
}
```

We will split the plots into 2 code chunks to reduce the number of graphs in a single output for a clearer view.

```{r}
tmap_mode("plot")
tmap_arrange(graphing("2021-07-01"),
             graphing("2021-08-01"),
             graphing("2021-09-01"),
             graphing("2021-10-01"),
             graphing("2021-11-01"),
             graphing("2021-12-01"),
             ncol = 2)
```

```{r}
tmap_arrange(graphing("2022-01-01"),
             graphing("2022-02-01"),
             graphing("2022-03-01"),
             graphing("2022-04-01"),
             graphing("2022-05-01"),
             graphing("2022-06-01"),
             ncol = 2)
```

Likewise, this can be done on Rshiny app but this will be covered on a later date when I have attended the Rshiny workshop. :)

## Spatial Patterns observed (200words)

# Local Gi\* Analysis

To bring you back, here is the task assigned in this section:

-   Compute local Gi\* values of the monthly vaccination rate,

-   Display the Gi\* maps of the monthly vaccination rate. The maps should only display the significant (i.e. p-value \< 0.05)

-   With reference to the analysis results, draw statistical conclusions (not more than 250 words)

## Computing Contiguity Spatial Weights

Before we can compute the global spatial autocorrelation statistics, we need to construct the spatial weights of the study area.

Spatial weights: Used to define the neighbourhood relationships between geographical units in the study area.

As we are dealing with 12 different months of vaccination rates, we will have to filter the dataframe to their respective months and calculate their respective weights. Here, we will be using the QUEEN mode and thus the argument: queen =TRUE. The code chunk below shows the function that filters to the selected month and then calculate their weights.

```{r}
month <- vaccination %>%
  filter(date == "2021-07-01")
wm_q <- month %>%
  na.exclude() %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
wm_q
```

## Computing local Moran's I

Next, we will use local_moran() of the sfdep package to calculate local Moran's I.

```{r}
set.seed(1234)
july_LGI <- wm_q %>%
  mutate(local_Gi = local_gstar_perm(vaccination_rate,
                                   nb,
                                   wt,
                                   nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
```

## Visualizing p-value of local Gi

```{r}
tmap_mode("plot")
tm_shape(july_LGI) +
    tm_polygons() +
    tm_shape(july_LGI %>% filter(p_sim <0.05)) +
    tm_fill("gi_star") +
    tm_borders(alpha = 0.5) +
    tm_layout(main.title = paste("significant local Gi", "(", july_LGI$date[1],")"),
              main.title.size = 0.8)
  return(plot)
```

## Putting it all together

As you follow along, these are the 3 main steps to creating the plots required for this section. As mentioned above, we will combine these 3 sections into a single function to calculate the local Gi for each month. The code chunk below takes in input "mth" to filter vaccination to the respective month and calculate the weights and the local Moran's I. \### Creating the local MI computation function

```{r}
lisa <- function(mth){
  set.seed(1234)
  month <- vaccination %>%
    filter(date ==mth)
  wm_q <- month %>%
    na.exclude() %>%
    mutate(nb = st_contiguity(geometry),
           wt = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1))
  result <- wm_q %>%
    mutate(local_gi = local_gstar_perm(vaccination_rate,
                                   nb,
                                   wt,
                                   nsim = 99),
           .before = 1) %>% 
    unnest(local_gi)
  return(result)
}
```

Now we will calculate the local Gi for each month and place it into a list for easy referencing for the plots later.

```{r}
date <- c("2021-07-01", "2021-08-01", "2021-09-01", "2021-10-01", "2021-11-01", "2021-12-01",
          "2022-01-01", "2022-02-01", "2022-03-01","2022-04-01", "2022-05-01", "2022-06-01")
lisa_GI <- list()
for (i in 1:12){
  lisa_GI[[i]] <- lisa(date[i])
}
```

Now we have a list of dataframes with local Moran I computed. Note that lisa_LMI\[\[1\]\] refers to July 2021, in ascending order.

### Creating the Tmap function

```{r}
graph_lisa <- function(x){
  HCSA_sig <- x %>%
    filter(p_sim <0.05)
  HCSA_plots <- tm_shape(x) +
    tm_polygons() +
    tm_borders(alpha = 0.5) +
    tm_shape(HCSA_sig) +
      tm_fill("gi_star",
              palette = "RdYlGn",
              midpoint = 0) +
      tm_borders(alpha = 0.4) +
    tm_layout(main.title = paste("significant local Gi", "(",x$date[1],")"),
              main.title.size = 0.8)
  return(HCSA_plots)
}
```

```{r}
tmap_mode("plot")
tmap_arrange(graph_lisa(lisa_GI[[1]]),
             graph_lisa(lisa_GI[[2]]),
             graph_lisa(lisa_GI[[3]]),
             graph_lisa(lisa_GI[[4]]),
             graph_lisa(lisa_GI[[5]]),
             graph_lisa(lisa_GI[[6]]),
             ncol =2)
```

```{r}
tmap_arrange(graph_lisa(lisa_GI[[7]]),
             graph_lisa(lisa_GI[[8]]),
             graph_lisa(lisa_GI[[9]]),
             graph_lisa(lisa_GI[[10]]),
             graph_lisa(lisa_GI[[11]]),
             graph_lisa(lisa_GI[[12]]),
             ncol =2)
```

## Statistical Conclusion (Not more than 250words) :

# Emerging Hot Spot Analysis (EHSA)

## Creating a Time Series Cube

The code chunk below creates a spatio-temporal cube by using spacetime() from the sfdep package.

```{r}
vaccination_rate_st<- as_spacetime(vaccination,
                                .loc_col = "village_code",
                                .time_col = "date")
```

```{r}
vaccination_rate_nb <- vaccination_rate_st %>%
  activate("geometry") %>%
  mutate(
    nb = include_self(st_contiguity(geometry)),
    wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
    .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")
```

```{r}
gi_stars <- vaccination_rate_nb %>%
  group_by(date) %>%
  mutate(vaccination_rate = as.numeric(vaccination_rate),
         gi_star = local_gstar_perm(vaccination_rate, 
                                    nb, 
                                    wt, 
                                    nsim = 99)) %>%
  tidyr::unnest(gi_star)
```

## Mann-Kendall Test

Subdistricts Chosen:

1.  3174101005
2.  3173031006
3.  3174091001

```{r}
cbg_1 <- gi_stars %>%
  ungroup() %>%
  filter(village_code == "3174101005") %>%
  select(date, village_code, gi_star)
```

```{r}
ggplot(data = cbg_1, 
       aes(x = date, 
           y = gi_star)) +
  geom_line() +
  theme_light()
```

```{r}
cbg_1 %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

```{r}
cbg_2 <- gi_stars %>%
  ungroup() %>%
  filter(village_code == "3173031006") %>%
  select(date, village_code, gi_star)
```

```{r}
ggplot(data = cbg_2, 
       aes(x = date, 
           y = gi_star)) +
  geom_line() +
  theme_light()

```

```{r}
cbg_2 %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

```{r}
cbg_3 <- gi_stars %>%
  ungroup() %>%
  filter(village_code == "3174091001") %>%
  select(date, village_code, gi_star)
```

```{r}
ggplot(data = cbg_3, 
       aes(x = date, 
           y = gi_star)) +
  geom_line() +
  theme_light()
```

```{r}
cbg_3 %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>% 
  tidyr::unnest_wider(mk)
```

```{r}
ehsa <- gi_stars %>%
  group_by(date) %>%
  summarise(mk = list(
    unclass(
      Kendall::MannKendall(gi_star)))) %>%
  tidyr::unnest_wider(mk)
```

```{r}
emerging <- ehsa %>% 
  arrange(sl, abs(tau)) %>% 
  slice(1:5)
```

## 

```{r}
ehsa <- emerging_hotspot_analysis(
  x = vaccination_rate_st,
  .var = "vaccination_rate",
  k = 1,
  nsim = 99
)
```

```{r}
ggplot(data = ehsa,
       aes(x = classification)) +
  geom_bar()
```

```{r}
vaccination_ehsa <- left_join(geoDKI, ehsa, by = c("village_code" = "location"))
```

```{r}
ehsa_sig <- vaccination_ehsa  %>%
  filter(p_value < 0.05)
tmap_mode("view")
tm_shape(vaccination_ehsa) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(ehsa_sig) +
  tm_fill("classification") + 
  tm_borders(alpha = 0.4)
```
