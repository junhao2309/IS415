---
title: "Take-home Exercise 3: Predicting HDB Public Housing Resale Pricies using Geographically Weighted Methods"
date: "6 March 2023"
date-modified: "`r Sys.Date()`"
number-sections: true
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# Setting the Scene

Housing is an essential component of household wealth worldwide.
Buying a housing has always been a major investment for most people.
The price of housing is affected by many factors.
Some of them are global in nature such as the general economy of a country or inflation rate.
Others can be more specific to the properties themselves.
These factors can be further divided to structural and locational factors.
Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property.
Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.

Conventional, housing resale prices predictive models were built by using [**Ordinary Least Square (OLS)**](https://en.wikipedia.org/wiki/Ordinary_least_squares) method.
However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions.
With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998).
In view of this limitation, **Geographical Weighted Models** were introduced for calibrating predictive model for housing resale prices.

## The Task

In this take-home exercise, you are tasked to predict HDB resale prices at the sub-market level (i.e.Â HDB 3-room, HDB 4-room and HDB 5-room) for the month of January and February 2023 in Singapore.
The predictive models must be built by using by using conventional OLS method and GWR methods.
You are also required to compare the performance of the conventional OLS method versus the geographical weighted methods.

## Packages used:

```{r}
pacman::p_load(tidyverse, sf, sfdep, tmap, httr, jsonlite, matrixStats, readr, readxl)
```

## Data used:

```{r}
# initialise a dataframe of our aspatial and geospatial dataset details
datasets <- data.frame(
  Type=c("Aspatial",
         "Geospatial",
         "Geospatial",
         "Geospatial",
         "Geospatial",
         
         "Geospatial - Extracted",
         "Geospatial - Extracted",
         "Geospatial - Extracted",
         "Geospatial - Extracted",
         "Geospatial - Extracted",
         "Geospatial - Extracted",
         "Geospatial - Extracted",
         
         "Geospatial - Selfsourced",
         "Geospatial - Selfsourced",
         "Geospatial - Selfsourced",
         "Geospatial - Selfsourced"),
  
  Name=c("Resale Flat Prices",
         "Singapore National Boundary",
         "Master Plan 2014 Subzone Boundary (Web)",
         "MRT & LRT Locations Aug 2021",
         "Bus Stop Locations Aug 2021",
         
         "Childcare Services",
         "Eldercare Services",
         "Hawker Centres",
         "Kindergartens",
         "Parks",
         "Supermarkets",
         "Primary Schools",
         
         "Community Health Assistance Scheme (CHAS) Clinics",
         "Integrated Screening Programme (ISP) Clinics",
         "Public, Private and Non-for-profit Hospitals",
         "Shopping Mall SVY21 Coordinates`"),
  
  Format=c(".csv", 
           ".shp", 
           ".shp", 
           ".shp", 
           ".shp",
           
           ".shp", 
           ".shp", 
           ".shp", 
           ".shp",
           ".shp", 
           ".shp",
           ".shp",
           
           ".kml",
           ".shp",
           ".xlsx",
           ".csv"),
  
  Source=c("[data.gov.sg](https://data.gov.sg/dataset/resale-flat-prices)",
           "[data.gov.sg](https://data.gov.sg/dataset/national-map-polygon)",
           "[data.gov.sg](https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web)",
           "[LTA Data Mall](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=Train)",
           "[LTA Data Mall](https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop)",
           
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           
           "[data.gov.sg](https://data.gov.sg/dataset/chas-clinics)",
           "[OneMap API](https://www.onemap.gov.sg/docs/)",
           "Self-sourced and collated (section 2.3)",
           "[Mall SVY21 Coordinates Web Scaper](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper)")
  )

# with reference to this guide on kableExtra:
# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html
# kable_material is the name of the kable theme
# 'hover' for to highlight row when hovering, 'scale_down' to adjust table to fit page width
library(knitr)
library(kableExtra)
kable(datasets, caption="Datasets Used") %>%
  kable_material("hover", latex_options="scale_down")

```

### How to extract data from onemap

These are the steps:

*The code chunks below uses onemapsgapi package.*

1.  Register an account with [onemap](https://developers.onemap.sg/register/)
2.  A code is then be sent to your email. Then fill in this [form](https://developers.onemap.sg/confirm_account/)
3.  In the console, run the code chunk below:

```{r, eval = FALSE}
token <- get_token("email", "password")
```

Input the email and password that you've registered with onemap.
This will provide you a token ID under objectname: token.
Note that you will need to do this again as the token is only valid for 3 days.

4.  Obtain queryname by running the code chunk below:

```{r, eval = FALSE}
themes <- search_themes(token)
```

Input your token ID and you can source for the queryname for Step 5.

5.  Use get_theme() to get the data from onemap

For this example, we will use queryname, "eldercare".

```{r, eval = FALSE}
eldercare<-get_theme(token,"eldercare")
```

6.  Convert the object into an sf object then download it into your data folder. st_as_sf() is for converting the file and st_write() is for writing the file into your folder. st_transform() sets the coordinate reference system to Singapore, EPSG::3414. These functions are from the sf package.

```{r, eval = FALSE}
eldercaresf <- st_as_sf(eldercare, coords=c("Lng", "Lat"), 
                        crs=4326) %>% 
  st_transform(crs = 3414)
st_write(obj = eldercaresf,
         dsn = "data/geospatial",
         layer = "eldercare",
         driver = "ESRI Shapefile")
```

To make it more automatic, define which variables you want from the onemap database into a vector.
The code chunk runs a for loop that does steps 5 and 6 together and stores them into your folder.

```{r, eval = FALSE}
onemap_variables <- c("eldercare","kindergartens", "hawkercentre", "communityclubs", "nationalparks","registered_pharmacy","family")

df <- list()
df_sf <- list()
for (i in 1:length(onemap_variables)){
  df[[i]] <- get_theme(token, onemap_variables[i])
  df_sf[[i]] <- st_as_sf(df[[i]], coords=c("Lng", "Lat"), 
                        crs=4326) %>%
    st_transform(crs = 3414)
st_write(obj = df_sf[[i]],
         dsn = "data/geospatial/Onemap",
         layer = onemap_variables[i],
         driver = "ESRI Shapefile")
}
```

# Load Data into R

## Geospatial Data

::: panel-tabset
### One-Map

```{r}
pharmacy <- st_read(dsn = "data/geospatial/Onemap",
                layer = "registered_pharmacy")
parks <- st_read(dsn = "data/geospatial/Onemap",
                 layer = "nationalparks")
kindergartens <- st_read(dsn = "data/geospatial/Onemap",
                    layer = "kindergartens")
hawker <- st_read(dsn = "data/geospatial/Onemap",
                    layer = "hawkercentre")
eldercare <- st_read(dsn = "data/geospatial/Onemap",
                    layer = "eldercare")
communityclubs <-st_read(dsn = "data/geospatial/Onemap",
                    layer = "communityclubs")
supermarkets <- st_read(dsn = "data/geospatial/Onemap",
                    layer = "SUPERMARKETS")
familyservices <- st_read(dsn = "data/geospatial/Onemap",
                    layer = "FAMILY")
```

### Geospatial Map

```{r}
mpsz <- st_read(dsn = "data/geospatial",
                layer = "MP14_SUBZONE_WEB_PL")
```

### DATA.GOV

```{r}
Bus_stop <- st_read(dsn = "data/geospatial",
                layer = "BusStop")
MRT <- st_read(dsn = "data/geospatial",
                layer = "RapidTransitSystemStation")
```

### Aspatial Data

```{r}
Resale <- read_csv("data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv")
```

```{r}
Primary_sch <- read_csv("data/aspatial/primaryschoolsg.csv")
```

```{r}
Secondary_sch <- read_csv("data/aspatial/secsch_cleaned.csv")
```

```{r}
Malls <- read_csv("data/aspatial/mall_coordinates_updated.csv")
```
:::

# Data Wrangling

## HDB Resale Price

For the purpose of this take-home exercise, we will only be using five-room flat and transaction period should be January and February 2023.

```{r}
glimpse(Resale)
```

From the output above, the variables we want are:

-   Resale Price
-   Area of the unit
-   Floor level
-   Remaining Lease
-   Age of the unit

We will first filter out the relevant columns we want by running the code chunk below:

select() helps to select the columns we want and filter() helps us to filter to the specific two months.
These two functions come from the dplyr package.

```{r}
Resale_2023 <- Resale %>%
  select(1,3,4,5,6,7,10,11) %>%
  mutate(month = as.Date(paste0(month, "-01"), format ="%Y-%m-%d")) %>%
  filter(month >= "2022-01-01" & month <= "2022-12-01",
         flat_type == "5 ROOM")
```

We also notice that the data type for story_range, flat_type and remaining_lease are chr type.
For story_range and flat_type, we should change them to factor while remaining lease should be made into a numeric.

We will first settle the remaining lease by running the code chunk below:

```{r}
# Splits the string by year and month, using str_split from the stringr package
str_list <- str_split(Resale_2023$remaining_lease, " ")

for (i in 1:length(str_list)) {
  if (length(unlist(str_list[i])) > 2) {
      year <- as.numeric(unlist(str_list[i])[1])
      month <- as.numeric(unlist(str_list[i])[3])
      Resale_2023$remaining_lease[i] <- year + round(month/12, 2)
  }
  else {
    year <- as.numeric(unlist(str_list[i])[1])
    Resale_2023$remaining_lease[i] <- year
  }
}
```

Once done, we will use mutate() to change the remaining two variables to the correct data type.

```{r}
Resale_2023 <-Resale_2023 %>%
  mutate(flat_type = as.factor(flat_type),
         storey_range = as.factor(storey_range),
         remaining_lease = as.numeric(remaining_lease))
glimpse(Resale_2023)
```

### Inserting geometries

To do this, we will have to obtain the geometries from this [url](https://developers.onemap.sg/commonapi/search).
This code is referenced from [Megan's work](https://is415-msty.netlify.app/posts/2021-10-25-take-home-exercise-3/).

```{r}
library("httr")
geocode <- function(block, streetname) {
  base_url <- "https://developers.onemap.sg/commonapi/search"
  address <- paste(block, streetname, sep = " ")
  query <- list("searchVal" = address, 
                "returnGeom" = "Y",
                "getAddrDetails" = "N",
                "pageNum" = "1")
  
  res <- GET(base_url, query = query)
  restext<-content(res, as="text")
  
  output <- jsonlite::fromJSON(restext)  %>% 
    as.data.frame() %>%
    dplyr::select("results.LATITUDE", "results.LONGITUDE")
  return(output)
}
```

```{r, eval = FALSE}
Resale_2023$LATITUDE <- 0
Resale_2023$LONGITUDE <- 0

for (i in 1:nrow(Resale_2023)){
  temp_output <- geocode(Resale_2023[i, 3], Resale_2023[i, 4])
  
  Resale_2023$LATITUDE[i] <- temp_output$results.LATITUDE
  Resale_2023$LONGITUDE[i] <- temp_output$results.LONGITUDE
}
```

### Convert into Resale_2023 dataframe into sf

By using st_as_sf() from the sf package, we can convert Resale_2023 into an sf and then transform the crs to EPSG:: 3414 which is the coordinate reference system for Singapore

```{r, eval = FALSE}
Resale_sf <- st_as_sf(Resale_2023, 
                      coords = c("LONGITUDE", "LATITUDE"),
                      crs = 4326) %>%
  st_transform(crs = 3414)
```

We can store it as a shapefile for future retrieval.

```{r,eval = FALSE}
st_write(Resale_sf, 
         dsn = "data/aspatial", 
         layer = "resale",
         driver = "ESRI Shapefile")
```

```{r}
Resale_sf <- st_read(dsn = "data/aspatial",
                     layer = "resale")
```

## Aspatial Data Wrangling

For Primary_sch, Secondary_sch and Mall, we need to convert them into sf and transform it to the correct CRS.

Primary School:

```{r}
Pri_sch <- Primary_sch %>%
  st_as_sf(coords = c("Latitude", "Longitude"),
           crs = 4326) %>% 
  st_transform(crs = 3414)
```

Secondary School:

```{r}
Sec_sch <- Secondary_sch %>%
  st_as_sf(coords = c("latitude", "longitude"),
           crs = 4326) %>% 
  st_transform(crs = 3414)
```

Malls:

```{r}
malls <- Malls %>%
  st_as_sf(coords = c("latitude", "longitude"),
           crs = 4326) %>% 
  st_transform(crs = 3414)
```

## Ensure all datasets are in EPSG:3414

Aside from the onemap variables, we need to check the geospatial data and the other data sets, primary school, secondary school and shopping malls.

```{r}
st_crs(mpsz) ; st_crs(Bus_stop) ; st_crs(MRT)
```

We notice that the CRS for these 3 geospatial data is not correct.
We will use st_transformed as taught previously to convert it to EPSG:3414

```{r}
mpsz <- mpsz %>%
  st_transform(crs = 4326) %>%
  st_transform(crs = 3414)
```

```{r}
Bus_stop <- Bus_stop %>%
  st_transform(crs = 4326) %>%
  st_transform(crs = 3414)
```

```{r}
MRT <- MRT %>%
  st_transform(crs = 4326) %>%
  st_transform(crs = 3414)
```

## Checking invalid geometries

We should also check for any invalid geometries

::: panel-tabset
### Onemap variable checks 

```{r}
length(which(st_is_valid(communityclubs)== FALSE))
```

```{r}
length(which(st_is_valid(eldercare)== FALSE))
```

```{r}
length(which(st_is_valid(familyservices)== FALSE))
```

```{r}
length(which(st_is_valid(hawker)== FALSE))
```

```{r}
length(which(st_is_valid(kindergartens)== FALSE))
```

```{r}
length(which(st_is_valid(parks)== FALSE))
```

```{r}
length(which(st_is_valid(pharmacy)== FALSE))
```

```{r}
length(which(st_is_valid(supermarkets)== FALSE))
```

We can see that for the oneMap variables, there are no invalid geometries.

### DATA.GOV

```{r}
length(which(st_is_valid(mpsz)== FALSE))
```

```{r}
length(which(st_is_valid(Bus_stop)== FALSE))
```

```{r}
length(which(st_is_valid(MRT)== FALSE))
```

For the data obtained from DATA.GOV, there are some invalid geometries

We will proceed to remove them

```{r}
mpsz <- st_make_valid(mpsz)
MRT <- st_make_valid(mpsz)
```
:::
